{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b32bc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Mathlib__Algebra__Ring__Subring__Pointwise.lean.pkl\n",
      "12680 examples loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "data_folder = '/home/mcwave/code/automath/atp/datasets/provability/mathlib4_states_w_proof/'\n",
    "file_names = os.listdir(data_folder)\n",
    "\n",
    "data = []\n",
    "\n",
    "count = 0\n",
    "for file_name in file_names:\n",
    "    if not file_name.endswith(\"pkl\"):\n",
    "        continue\n",
    "    if not 'Algebra' in file_name:\n",
    "        continue\n",
    "    count += 1\n",
    "    if count <= 5:\n",
    "        continue\n",
    "    print(\"Loading\", file_name)\n",
    "    file_path = os.path.join(data_folder, file_name)\n",
    "    fin = open(file_path, 'rb')\n",
    "    while True:\n",
    "        try:\n",
    "            pair = pickle.load(fin)\n",
    "            data.append(pair) #(pair[1][0], pair[1][2][0]))\n",
    "        except:\n",
    "            break\n",
    "    break\n",
    "\n",
    "print(len(data), \"examples loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22d57ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('https://github.com/leanprover-community/mathlib4',\n",
       "  '27c6744e1c0e25d676be5eb252cd4b6d30c6acc7',\n",
       "  'Mathlib/Algebra/Ring/Subring/Pointwise.lean',\n",
       "  'Subring.pointwise_smul_def'),\n",
       " ('case h\\nM : Type u_1\\nR : Type u_2\\ninst✝² : Monoid M\\ninst✝¹ : Ring R\\ninst✝ : MulSemiringAction M R\\na : M\\nS : Subring R\\nnvar0 : R\\n⊢ nvar0 ∈ SMul.smul a S ↔ nvar0 ∈ map (MulSemiringAction.toRingHom M R a) S',\n",
       "  2,\n",
       "  ['simp_rw [mem_map]', 'exact']))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "782ea1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATE_PP:\n",
      "case h\n",
      "M : Type u_1\n",
      "R : Type u_2\n",
      "inst✝² : Monoid M\n",
      "inst✝¹ : Ring R\n",
      "inst✝ : MulSemiringAction M R\n",
      "a : M\n",
      "S : Subring R\n",
      "nvar0 : R\n",
      "⊢ nvar0 ∈ map (MulSemiringAction.toRingHom M R a) S ↔ nvar0 ∈ a • S\n",
      "TACTICS:\n",
      "symm\n",
      "simp [eq_comm (a := a)]\n",
      "cases S\n",
      "rw [smul_neg]\n",
      "rw [← eq_f₀']\n",
      "STATE_PP:\n",
      "theorem Subring.pointwise_smul_def (M: Type u_1) (R: Type u_2) (inst✝²: Monoid M) (inst✝¹: Ring R) (inst✝: MulSemiringAction M R) (a: M) (S: Subring R) (nvar0: R) : nvar0 ∈ map (MulSemiringAction.toRingHom M R a) S ↔ nvar0 ∈ a • S :=\n",
      "\n",
      "HYPOTHESES:\n",
      " []\n"
     ]
    }
   ],
   "source": [
    "from utils.lean_math_utils import *\n",
    "from utils.lean_theorem_utils import *\n",
    "\n",
    "def count_lines(string):\n",
    "    # Split the string into lines\n",
    "    lines = string.splitlines()\n",
    "    # Count the number of lines\n",
    "    return len(lines)\n",
    "\n",
    "def extract_first_case(state_pp):\n",
    "    state_pp = state_pp.strip()\n",
    "    if not state_pp.startswith('case'):\n",
    "        return state_pp\n",
    "    lines = state_pp.split('\\n')\n",
    "    first_case = []\n",
    "    for line in lines[1:]:\n",
    "        if line.strip().startswith('case'):\n",
    "            break\n",
    "        if line.strip() != '':\n",
    "            first_case.append(line)\n",
    "    return '\\n'.join(first_case)\n",
    "\n",
    "\n",
    "# Params:\n",
    "#   hyp: tuple(name, type)\n",
    "#   tactics: list(tactic)\n",
    "def is_hypothesis_useful(hyp, tactics):\n",
    "    for tactic in tactics:\n",
    "        tokens = tokenize_lean_tactic(tactic)\n",
    "        if hyp[0] in tokens:\n",
    "            idx = tokens.index(hyp[0])\n",
    "            if idx > 0:\n",
    "                if hyp[0].startswith('h'):\n",
    "                    return True\n",
    "                if tokens[idx - 1] == 'exact':\n",
    "                    return True\n",
    "                if tokens[idx - 1] == 'at':\n",
    "                    return True\n",
    "                if tokens[idx - 1] == '[':\n",
    "                    return True\n",
    "                if idx < len(tokens) - 1 and tokens[idx + 1] == ']':\n",
    "                    return True\n",
    "                for operator in TargetNode.operators:\n",
    "                    if operator in hyp[1]:\n",
    "                        return True\n",
    "    return False\n",
    "\n",
    "def create_hypothesis_predict_data(raw_state_pp, tactics, theorem_name):\n",
    "    is_case = raw_state_pp.strip().startswith('case')\n",
    "    state_pp = extract_first_case(raw_state_pp)\n",
    "    if is_case and count_lines(state_pp) < count_lines(raw_state_pp) - 2:\n",
    "        tactics = tactics[0:1]\n",
    "    #\n",
    "    premise = Premise()\n",
    "    premise.theorem_name = theorem_name\n",
    "    premise.parse_state(state_pp)\n",
    "    #\n",
    "    useful_hypotheses, useless_hypotheses = [], OrderedDict()\n",
    "    for hyp in premise.hypotheses.items():\n",
    "        useful = is_hypothesis_useful(hyp, tactics)\n",
    "        if useful:\n",
    "            #print(\"YES:\", hyp)\n",
    "            useful_hypotheses.append(hyp)\n",
    "        else:\n",
    "            #print(\"NO :\", hyp)\n",
    "            useless_hypotheses[hyp[0]] = hyp[1]\n",
    "    premise.hypotheses = useless_hypotheses\n",
    "    return premise, useful_hypotheses\n",
    "\n",
    "idx = 120\n",
    "\n",
    "state_pp = data[idx][1][0]\n",
    "tactics = data[idx][1][2]\n",
    "theorem_name = data[idx][0][3]\n",
    "\n",
    "print(\"STATE_PP:\\n\" + state_pp)\n",
    "\n",
    "print(\"TACTICS:\\n\" + \"\\n\".join(tactics))\n",
    "\n",
    "premise, useful_hypotheses = create_hypothesis_predict_data(state_pp, tactics, theorem_name)\n",
    "\n",
    "print(\"STATE_PP:\\n\" + premise.to_theorem_code())\n",
    "print(\"\\nHYPOTHESES:\\n\", useful_hypotheses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2bca981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Mathlib__Algebra__Category__ModuleCat__Presheaf.lean.pkl\n",
      "50933 examples loaded\n",
      "10302 hypotheses data found\n",
      "Loading Mathlib__Algebra__BigOperators__Pi.lean.pkl\n",
      "31644 examples loaded\n",
      "7145 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__ModuleCat__EpiMono.lean.pkl\n",
      "20 examples loaded\n",
      "0 hypotheses data found\n",
      "Loading Mathlib__Algebra__DirectSum__Decomposition.lean.pkl\n",
      "55012 examples loaded\n",
      "14902 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__GroupCat__Biproducts.lean.pkl\n",
      "10067 examples loaded\n",
      "326 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__FGModuleCat__Basic.lean.pkl\n",
      "57302 examples loaded\n",
      "20074 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Basic.lean.pkl\n",
      "1432363 examples loaded\n",
      "345282 hypotheses data found\n",
      "Loading Mathlib__Algebra__Algebra__Hom.lean.pkl\n",
      "310093 examples loaded\n",
      "50818 hypotheses data found\n",
      "Loading Mathlib__Algebra__BigOperators__Fin.lean.pkl\n",
      "37812 examples loaded\n",
      "10195 hypotheses data found\n",
      "Loading Mathlib__Algebra__BigOperators__Group__Multiset.lean.pkl\n",
      "35754 examples loaded\n",
      "4704 hypotheses data found\n",
      "Loading Mathlib__Algebra__CharP__Defs.lean.pkl\n",
      "21911 examples loaded\n",
      "557 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__ModuleCat__Monoidal__Symmetric.lean.pkl\n",
      "2800 examples loaded\n",
      "0 hypotheses data found\n",
      "Loading Mathlib__Algebra__Algebra__Tower.lean.pkl\n",
      "97543 examples loaded\n",
      "10019 hypotheses data found\n",
      "Loading Mathlib__Algebra__GCDMonoid__IntegrallyClosed.lean.pkl\n",
      "14 examples loaded\n",
      "5 hypotheses data found\n",
      "Loading Mathlib__Algebra__Field__Power.lean.pkl\n",
      "52 examples loaded\n",
      "26 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__ModuleCat__ChangeOfRings.lean.pkl\n",
      "47969 examples loaded\n",
      "17840 hypotheses data found\n",
      "Loading Mathlib__Algebra__CharP__Invertible.lean.pkl\n",
      "4 examples loaded\n",
      "0 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Commute__Units.lean.pkl\n",
      "6912 examples loaded\n",
      "1566 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Nat.lean.pkl\n",
      "32029 examples loaded\n",
      "757 hypotheses data found\n",
      "Loading Mathlib__Algebra__BigOperators__GroupWithZero__Finset.lean.pkl\n",
      "10458 examples loaded\n",
      "661 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__ModuleCat__Kernels.lean.pkl\n",
      "7084 examples loaded\n",
      "181 hypotheses data found\n",
      "Loading Mathlib__Algebra__Algebra__Defs.lean.pkl\n",
      "119089 examples loaded\n",
      "5454 hypotheses data found\n",
      "Loading Mathlib__Algebra__CharP__Reduced.lean.pkl\n",
      "24 examples loaded\n",
      "4 hypotheses data found\n",
      "Loading Mathlib__Algebra__BigOperators__Module.lean.pkl\n",
      "24 examples loaded\n",
      "11 hypotheses data found\n",
      "Loading Mathlib__Algebra__DualNumber.lean.pkl\n",
      "56572 examples loaded\n",
      "21642 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Commute__Basic.lean.pkl\n",
      "22447 examples loaded\n",
      "5903 hypotheses data found\n",
      "Loading Mathlib__Algebra__Algebra__Subalgebra__Prod.lean.pkl\n",
      "16225 examples loaded\n",
      "2638 hypotheses data found\n",
      "Loading Mathlib__Algebra__Algebra__Opposite.lean.pkl\n",
      "107761 examples loaded\n",
      "18906 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__SemigroupCat__Basic.lean.pkl\n",
      "66590 examples loaded\n",
      "40470 hypotheses data found\n",
      "Loading Mathlib__Algebra__GradedMonoid.lean.pkl\n",
      "124866 examples loaded\n",
      "59032 hypotheses data found\n",
      "Loading Mathlib__Algebra__EuclideanDomain__Defs.lean.pkl\n",
      "16311 examples loaded\n",
      "3357 hypotheses data found\n",
      "Loading Mathlib__Algebra__Algebra__Subalgebra__MulOpposite.lean.pkl\n",
      "88521 examples loaded\n",
      "8970 hypotheses data found\n",
      "Loading Mathlib__Algebra__DirectSum__Internal.lean.pkl\n",
      "13251 examples loaded\n",
      "854 hypotheses data found\n",
      "Loading Mathlib__Algebra__ContinuedFractions__Computation__TerminatesIffRat.lean.pkl\n",
      "2848 examples loaded\n",
      "610 hypotheses data found\n",
      "Loading Mathlib__Algebra__ContinuedFractions__Basic.lean.pkl\n",
      "13335 examples loaded\n",
      "6974 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__GroupCat__FilteredColimits.lean.pkl\n",
      "1587 examples loaded\n",
      "398 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Subgroup__Finite.lean.pkl\n",
      "13481 examples loaded\n",
      "659 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Semiconj__Basic.lean.pkl\n",
      "64 examples loaded\n",
      "22 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Int.lean.pkl\n",
      "45345 examples loaded\n",
      "4651 hypotheses data found\n",
      "Loading Mathlib__Algebra__ContinuedFractions__Translations.lean.pkl\n",
      "55515 examples loaded\n",
      "7169 hypotheses data found\n",
      "Loading Mathlib__Algebra__Divisibility__Basic.lean.pkl\n",
      "65925 examples loaded\n",
      "11396 hypotheses data found\n",
      "Loading Mathlib__Algebra__BigOperators__RingEquiv.lean.pkl\n",
      "6790 examples loaded\n",
      "1429 hypotheses data found\n",
      "Loading Mathlib__Algebra__AddConstMap__Basic.lean.pkl\n",
      "137536 examples loaded\n",
      "29858 hypotheses data found\n",
      "Loading Mathlib__Algebra__Algebra__NonUnitalSubalgebra.lean.pkl\n",
      "366764 examples loaded\n",
      "55421 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Subgroup__Basic.lean.pkl\n",
      "727097 examples loaded\n",
      "106921 hypotheses data found\n",
      "Loading Mathlib__Algebra__Algebra__Subalgebra__Operations.lean.pkl\n",
      "16 examples loaded\n",
      "8 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__ModuleCat__Presheaf__Sheafification.lean.pkl\n",
      "5326 examples loaded\n",
      "832 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Invertible__Defs.lean.pkl\n",
      "165699 examples loaded\n",
      "45267 hypotheses data found\n",
      "Loading Mathlib__Algebra__AlgebraicCard.lean.pkl\n",
      "96 examples loaded\n",
      "12 hypotheses data found\n",
      "Loading Mathlib__Algebra__Field__Defs.lean.pkl\n",
      "11160 examples loaded\n",
      "2271 hypotheses data found\n",
      "Loading Mathlib__Algebra__Exact.lean.pkl\n",
      "26465 examples loaded\n",
      "16049 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__GroupCat__Adjunctions.lean.pkl\n",
      "22033 examples loaded\n",
      "14144 hypotheses data found\n",
      "Loading Mathlib__Algebra__DirectSum__Basic.lean.pkl\n",
      "45153 examples loaded\n",
      "21271 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__ModuleCat__Sheaf.lean.pkl\n",
      "12439 examples loaded\n",
      "1603 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Hom__End.lean.pkl\n",
      "28332 examples loaded\n",
      "350 hypotheses data found\n",
      "Loading Mathlib__Algebra__Algebra__Subalgebra__Tower.lean.pkl\n",
      "36875 examples loaded\n",
      "1201 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Commutator.lean.pkl\n",
      "120 examples loaded\n",
      "0 hypotheses data found\n",
      "Loading Mathlib__Algebra__DirectSum__Module.lean.pkl\n",
      "77815 examples loaded\n",
      "39792 hypotheses data found\n",
      "Loading Mathlib__Algebra__Algebra__Unitization.lean.pkl\n",
      "338156 examples loaded\n",
      "117693 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__ModuleCat__Abelian.lean.pkl\n",
      "8 examples loaded\n",
      "0 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Hom__Basic.lean.pkl\n",
      "95601 examples loaded\n",
      "10803 hypotheses data found\n",
      "Loading Mathlib__Algebra__CharP__Basic.lean.pkl\n",
      "208 examples loaded\n",
      "49 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__ModuleCat__Presheaf__Limits.lean.pkl\n",
      "6 examples loaded\n",
      "0 hypotheses data found\n",
      "Loading Mathlib__Algebra__DirectSum__Ring.lean.pkl\n",
      "67886 examples loaded\n",
      "38108 hypotheses data found\n",
      "Loading Mathlib__Algebra__Algebra__Bilinear.lean.pkl\n",
      "83499 examples loaded\n",
      "14757 hypotheses data found\n",
      "Loading Mathlib__Algebra__DirectSum__LinearMap.lean.pkl\n",
      "160 examples loaded\n",
      "78 hypotheses data found\n",
      "Loading Mathlib__Algebra__FreeNonUnitalNonAssocAlgebra.lean.pkl\n",
      "17012 examples loaded\n",
      "243 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__Ring__Colimits.lean.pkl\n",
      "15312 examples loaded\n",
      "0 hypotheses data found\n",
      "Loading Mathlib__Algebra__BigOperators__Ring__Multiset.lean.pkl\n",
      "11226 examples loaded\n",
      "5486 hypotheses data found\n",
      "Loading Mathlib__Algebra__BigOperators__Finsupp.lean.pkl\n",
      "109695 examples loaded\n",
      "9346 hypotheses data found\n",
      "Loading Mathlib__Algebra__BigOperators__WithTop.lean.pkl\n",
      "32 examples loaded\n",
      "0 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Centralizer.lean.pkl\n",
      "37402 examples loaded\n",
      "11299 hypotheses data found\n",
      "Loading Mathlib__Algebra__Algebra__Subalgebra__Basic.lean.pkl\n",
      "545200 examples loaded\n",
      "73658 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__GroupCat__Limits.lean.pkl\n",
      "3453 examples loaded\n",
      "1659 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__ModuleCat__Sheaf__Limits.lean.pkl\n",
      "4 examples loaded\n",
      "2 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Subgroup__ZPowers.lean.pkl\n",
      "66762 examples loaded\n",
      "3064 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Action__Defs.lean.pkl\n",
      "185998 examples loaded\n",
      "82241 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Hom__Instances.lean.pkl\n",
      "53911 examples loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8837 hypotheses data found\n",
      "Loading Mathlib__Algebra__Algebra__Subalgebra__Directed.lean.pkl\n",
      "15341 examples loaded\n",
      "9637 hypotheses data found\n",
      "Loading Mathlib__Algebra__FreeAlgebra.lean.pkl\n",
      "18622 examples loaded\n",
      "3703 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__ModuleCat__Presheaf__Sheafify.lean.pkl\n",
      "106 examples loaded\n",
      "26 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__ModuleCat__Algebra.lean.pkl\n",
      "218 examples loaded\n",
      "21 hypotheses data found\n",
      "Loading Mathlib__Algebra__Algebra__Basic.lean.pkl\n",
      "173728 examples loaded\n",
      "13205 hypotheses data found\n",
      "Loading Mathlib__Algebra__BigOperators__Finprod.lean.pkl\n",
      "46121 examples loaded\n",
      "18646 hypotheses data found\n",
      "Loading Mathlib__Algebra__Algebra__NonUnitalHom.lean.pkl\n",
      "260187 examples loaded\n",
      "42581 hypotheses data found\n",
      "Loading Mathlib__Algebra__CharP__MixedCharZero.lean.pkl\n",
      "2351 examples loaded\n",
      "876 hypotheses data found\n",
      "Loading Mathlib__Algebra__DirectSum__Finsupp.lean.pkl\n",
      "3352 examples loaded\n",
      "101 hypotheses data found\n",
      "Loading Mathlib__Algebra__GroupPower__IterateHom.lean.pkl\n",
      "20963 examples loaded\n",
      "3184 hypotheses data found\n",
      "Loading Mathlib__Algebra__Algebra__Subalgebra__Rank.lean.pkl\n",
      "186 examples loaded\n",
      "45 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__GroupCat__Images.lean.pkl\n",
      "3465 examples loaded\n",
      "355 hypotheses data found\n",
      "Loading Mathlib__Algebra__Algebra__Subalgebra__Unitization.lean.pkl\n",
      "64545 examples loaded\n",
      "3707 hypotheses data found\n",
      "Loading Mathlib__Algebra__CharP__Two.lean.pkl\n",
      "110034 examples loaded\n",
      "1532 hypotheses data found\n",
      "Loading Mathlib__Algebra__CharP__ExpChar.lean.pkl\n",
      "88791 examples loaded\n",
      "2035 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__ModuleCat__FilteredColimits.lean.pkl\n",
      "7179 examples loaded\n",
      "4153 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__GroupCat__Basic.lean.pkl\n",
      "157528 examples loaded\n",
      "54145 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Semiconj__Defs.lean.pkl\n",
      "6598 examples loaded\n",
      "38 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Subgroup__Actions.lean.pkl\n",
      "1316 examples loaded\n",
      "12 hypotheses data found\n",
      "Loading Mathlib__Algebra__BigOperators__NatAntidiagonal.lean.pkl\n",
      "15948 examples loaded\n",
      "2079 hypotheses data found\n",
      "Loading Mathlib__Algebra__Associated.lean.pkl\n",
      "184975 examples loaded\n",
      "34441 hypotheses data found\n",
      "Loading Mathlib__Algebra__GCDMonoid__Nat.lean.pkl\n",
      "27153 examples loaded\n",
      "3187 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__Ring__Basic.lean.pkl\n",
      "292648 examples loaded\n",
      "49580 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__Ring__Constructions.lean.pkl\n",
      "12370 examples loaded\n",
      "1438 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Embedding.lean.pkl\n",
      "4042 examples loaded\n",
      "588 hypotheses data found\n",
      "Loading Mathlib__Algebra__BigOperators__Ring.lean.pkl\n",
      "42787 examples loaded\n",
      "3157 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__GroupWithZeroCat.lean.pkl\n",
      "8524 examples loaded\n",
      "164 hypotheses data found\n",
      "Loading Mathlib__Algebra__ContinuedFractions__Computation__CorrectnessTerminating.lean.pkl\n",
      "82 examples loaded\n",
      "16 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__ModuleCat__Images.lean.pkl\n",
      "2565 examples loaded\n",
      "52 hypotheses data found\n",
      "Loading Mathlib__Algebra__CharP__LocalRing.lean.pkl\n",
      "16 examples loaded\n",
      "7 hypotheses data found\n",
      "Loading Mathlib__Algebra__Field__Basic.lean.pkl\n",
      "206393 examples loaded\n",
      "39779 hypotheses data found\n",
      "Loading Mathlib__Algebra__EuclideanDomain__Basic.lean.pkl\n",
      "32810 examples loaded\n",
      "7224 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Aut.lean.pkl\n",
      "112636 examples loaded\n",
      "20142 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Commute__Hom.lean.pkl\n",
      "2094 examples loaded\n",
      "294 hypotheses data found\n",
      "Loading Mathlib__Algebra__CharP__CharAndCard.lean.pkl\n",
      "38 examples loaded\n",
      "19 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Conj.lean.pkl\n",
      "51529 examples loaded\n",
      "7726 hypotheses data found\n",
      "Loading Mathlib__Algebra__BigOperators__Intervals.lean.pkl\n",
      "15074 examples loaded\n",
      "3388 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Fin.lean.pkl\n",
      "15934 examples loaded\n",
      "1583 hypotheses data found\n",
      "Loading Mathlib__Algebra__Algebra__Spectrum.lean.pkl\n",
      "20390 examples loaded\n",
      "580 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Semiconj__Units.lean.pkl\n",
      "2362 examples loaded\n",
      "559 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__ModuleCat__Projective.lean.pkl\n",
      "8 examples loaded\n",
      "2 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__PNatPowAssoc.lean.pkl\n",
      "36 examples loaded\n",
      "12 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__BoolRing.lean.pkl\n",
      "13339 examples loaded\n",
      "8073 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__NatPowAssoc.lean.pkl\n",
      "62 examples loaded\n",
      "1 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Invertible__Basic.lean.pkl\n",
      "6964 examples loaded\n",
      "1545 hypotheses data found\n",
      "Loading Mathlib__Algebra__ContinuedFractions__Computation__Basic.lean.pkl\n",
      "2730 examples loaded\n",
      "117 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Indicator.lean.pkl\n",
      "115054 examples loaded\n",
      "51335 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__ModuleCat__Presheaf__Colimits.lean.pkl\n",
      "6 examples loaded\n",
      "0 hypotheses data found\n",
      "Loading Mathlib__Algebra__CharP__Quotient.lean.pkl\n",
      "28 examples loaded\n",
      "1 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__Ring__Adjunctions.lean.pkl\n",
      "27109 examples loaded\n",
      "15792 hypotheses data found\n",
      "Loading Mathlib__Algebra__ContinuedFractions__Computation__Translations.lean.pkl\n",
      "22561 examples loaded\n",
      "1737 hypotheses data found\n",
      "Loading Mathlib__Algebra__Algebra__Quasispectrum.lean.pkl\n",
      "49834 examples loaded\n",
      "8704 hypotheses data found\n",
      "Loading Mathlib__Algebra__FreeMonoid__Basic.lean.pkl\n",
      "203985 examples loaded\n",
      "46904 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Even.lean.pkl\n",
      "27707 examples loaded\n",
      "2024 hypotheses data found\n",
      "Loading Mathlib__Algebra__Algebra__RestrictScalars.lean.pkl\n",
      "41501 examples loaded\n",
      "1480 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__GroupCat__Abelian.lean.pkl\n",
      "14 examples loaded\n",
      "0 hypotheses data found\n",
      "Loading Mathlib__Algebra__GeomSum.lean.pkl\n",
      "41755 examples loaded\n",
      "2183 hypotheses data found\n",
      "Loading Mathlib__Algebra__Algebra__Prod.lean.pkl\n",
      "30970 examples loaded\n",
      "1377 hypotheses data found\n",
      "Loading Mathlib__Algebra__Divisibility__Units.lean.pkl\n",
      "14946 examples loaded\n",
      "2271 hypotheses data found\n",
      "Loading Mathlib__Algebra__BigOperators__Ring__List.lean.pkl\n",
      "5853 examples loaded\n",
      "2449 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__ModuleCat__Basic.lean.pkl\n",
      "81289 examples loaded\n",
      "22096 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__CoalgebraCat__Basic.lean.pkl\n",
      "66774 examples loaded\n",
      "13513 hypotheses data found\n",
      "Loading Mathlib__Algebra__Algebra__Subalgebra__Pointwise.lean.pkl\n",
      "17029 examples loaded\n",
      "1398 hypotheses data found\n",
      "Loading Mathlib__Algebra__Divisibility__Prod.lean.pkl\n",
      "24 examples loaded\n",
      "7 hypotheses data found\n",
      "Loading Mathlib__Algebra__Field__Opposite.lean.pkl\n",
      "30257 examples loaded\n",
      "15308 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__AlgebraCat__Monoidal.lean.pkl\n",
      "1159 examples loaded\n",
      "207 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__AlgebraCat__Basic.lean.pkl\n",
      "46735 examples loaded\n",
      "12533 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__ModuleCat__Presheaf__Pushforward.lean.pkl\n",
      "5830 examples loaded\n",
      "1091 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Commute__Defs.lean.pkl\n",
      "55815 examples loaded\n",
      "17089 hypotheses data found\n",
      "Loading Mathlib__Algebra__Field__IsField.lean.pkl\n",
      "3578 examples loaded\n",
      "1088 hypotheses data found\n",
      "Loading Mathlib__Algebra__DirectLimit.lean.pkl\n",
      "5073 examples loaded\n",
      "3201 hypotheses data found\n",
      "Loading Mathlib__Algebra__DualQuaternion.lean.pkl\n",
      "74416 examples loaded\n",
      "5844 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Ext.lean.pkl\n",
      "33580 examples loaded\n",
      "17418 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Submonoid__Membership.lean.pkl\n",
      "78147 examples loaded\n",
      "10743 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__GroupCat__Preadditive.lean.pkl\n",
      "4413 examples loaded\n",
      "283 hypotheses data found\n",
      "Loading Mathlib__Algebra__CubicDiscriminant.lean.pkl\n",
      "90083 examples loaded\n",
      "19500 hypotheses data found\n",
      "Loading Mathlib__Algebra__ContinuedFractions__ContinuantsRecurrence.lean.pkl\n",
      "42 examples loaded\n",
      "19 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Center.lean.pkl\n",
      "1256 examples loaded\n",
      "128 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Hom__Defs.lean.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "542499 examples loaded\n",
      "166521 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__MonCat__FilteredColimits.lean.pkl\n",
      "56 examples loaded\n",
      "24 hypotheses data found\n",
      "Loading Mathlib__Algebra__GCDMonoid__Multiset.lean.pkl\n",
      "20993 examples loaded\n",
      "1760 hypotheses data found\n",
      "Loading Mathlib__Algebra__ContinuedFractions__Computation__ApproximationCorollaries.lean.pkl\n",
      "42 examples loaded\n",
      "8 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Pi__Basic.lean.pkl\n",
      "240192 examples loaded\n",
      "43047 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__ModuleCat__Monoidal__Basic.lean.pkl\n",
      "28095 examples loaded\n",
      "5460 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__GroupCat__Colimits.lean.pkl\n",
      "9575 examples loaded\n",
      "1899 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Prod.lean.pkl\n",
      "452050 examples loaded\n",
      "52490 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__ModuleCat__Products.lean.pkl\n",
      "728 examples loaded\n",
      "0 hypotheses data found\n",
      "Loading Mathlib__Algebra__BigOperators__Group__List.lean.pkl\n",
      "78697 examples loaded\n",
      "34033 hypotheses data found\n",
      "Loading Mathlib__Algebra__GCDMonoid__Finset.lean.pkl\n",
      "51164 examples loaded\n",
      "3173 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__GroupCat__Zero.lean.pkl\n",
      "12 examples loaded\n",
      "0 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Defs.lean.pkl\n",
      "127889 examples loaded\n",
      "20702 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Submonoid__Basic.lean.pkl\n",
      "148683 examples loaded\n",
      "40876 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__ModuleCat__Subobject.lean.pkl\n",
      "30 examples loaded\n",
      "4 hypotheses data found\n",
      "Loading Mathlib__Algebra__GradedMulAction.lean.pkl\n",
      "17464 examples loaded\n",
      "6946 hypotheses data found\n",
      "Loading Mathlib__Algebra__CharZero__Defs.lean.pkl\n",
      "23893 examples loaded\n",
      "655 hypotheses data found\n",
      "Loading Mathlib__Algebra__Field__Subfield.lean.pkl\n",
      "227910 examples loaded\n",
      "30438 hypotheses data found\n",
      "Loading Mathlib__Algebra__GCDMonoid__Basic.lean.pkl\n",
      "116591 examples loaded\n",
      "10260 hypotheses data found\n",
      "Loading Mathlib__Algebra__DirectSum__Algebra.lean.pkl\n",
      "26841 examples loaded\n",
      "9152 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__MonCat__Colimits.lean.pkl\n",
      "8734 examples loaded\n",
      "5870 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__AddChar.lean.pkl\n",
      "157789 examples loaded\n",
      "10701 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__ModuleCat__Free.lean.pkl\n",
      "196 examples loaded\n",
      "91 hypotheses data found\n",
      "Loading Mathlib__Algebra__CharP__Algebra.lean.pkl\n",
      "1790 examples loaded\n",
      "544 hypotheses data found\n",
      "Loading Mathlib__Algebra__BigOperators__Associated.lean.pkl\n",
      "1894 examples loaded\n",
      "362 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__ModuleCat__Biproducts.lean.pkl\n",
      "6721 examples loaded\n",
      "251 hypotheses data found\n",
      "Loading Mathlib__Algebra__ContinuedFractions__TerminatedStable.lean.pkl\n",
      "46 examples loaded\n",
      "19 hypotheses data found\n",
      "Loading Mathlib__Algebra__BigOperators__Option.lean.pkl\n",
      "3649 examples loaded\n",
      "583 hypotheses data found\n",
      "Loading Mathlib__Algebra__Bounds.lean.pkl\n",
      "10739 examples loaded\n",
      "2186 hypotheses data found\n",
      "Loading Mathlib__Algebra__AddTorsor.lean.pkl\n",
      "257655 examples loaded\n",
      "53486 hypotheses data found\n",
      "Loading Mathlib__Algebra__CharZero__Quotient.lean.pkl\n",
      "68 examples loaded\n",
      "30 hypotheses data found\n",
      "Loading Mathlib__Algebra__Algebra__Pi.lean.pkl\n",
      "79765 examples loaded\n",
      "12792 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Subgroup__MulOpposite.lean.pkl\n",
      "73866 examples loaded\n",
      "5593 hypotheses data found\n",
      "Loading Mathlib__Algebra__FreeMonoid__Count.lean.pkl\n",
      "8401 examples loaded\n",
      "513 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__GroupCat__EpiMono.lean.pkl\n",
      "17491 examples loaded\n",
      "10243 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Equiv__Basic.lean.pkl\n",
      "293992 examples loaded\n",
      "114205 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Subgroup__Pointwise.lean.pkl\n",
      "34985 examples loaded\n",
      "2668 hypotheses data found\n",
      "Loading Mathlib__Algebra__Algebra__Equiv.lean.pkl\n",
      "393103 examples loaded\n",
      "107994 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Hom__CompTypeclasses.lean.pkl\n",
      "12 examples loaded\n",
      "4 hypotheses data found\n",
      "Loading Mathlib__Algebra__Free.lean.pkl\n",
      "301708 examples loaded\n",
      "68362 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__ModuleCat__Monoidal__Closed.lean.pkl\n",
      "11129 examples loaded\n",
      "2028 hypotheses data found\n",
      "Loading Mathlib__Algebra__CharZero__Lemmas.lean.pkl\n",
      "94324 examples loaded\n",
      "4313 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__BialgebraCat__Basic.lean.pkl\n",
      "69488 examples loaded\n",
      "12573 hypotheses data found\n",
      "Loading Mathlib__Algebra__BigOperators__Group__Finset.lean.pkl\n",
      "265049 examples loaded\n",
      "69876 hypotheses data found\n",
      "Loading Mathlib__Algebra__Field__ULift.lean.pkl\n",
      "13286 examples loaded\n",
      "4362 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Opposite.lean.pkl\n",
      "109132 examples loaded\n",
      "30462 hypotheses data found\n",
      "Loading Mathlib__Algebra__ContinuedFractions__ConvergentsEquiv.lean.pkl\n",
      "66 examples loaded\n",
      "16 hypotheses data found\n",
      "Loading Mathlib__Algebra__Group__Pi__Lemmas.lean.pkl\n",
      "128180 examples loaded\n",
      "22421 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__ModuleCat__Adjunctions.lean.pkl\n",
      "13645 examples loaded\n",
      "3252 hypotheses data found\n",
      "Loading Mathlib__Algebra__Category__MonCat__Basic.lean.pkl\n",
      "91120 examples loaded\n",
      "36805 hypotheses data found\n",
      "Loading Mathlib__Algebra__ContinuedFractions__Computation__Approximations.lean.pkl\n",
      "298 examples loaded\n",
      "124 hypotheses data found\n",
      "Loading Mathlib__Algebra__Algebra__Operations.lean.pkl\n",
      "66057 examples loaded\n",
      "3815 hypotheses data found\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import pickle\n",
    "\n",
    "# data_folder = '/home/mcwave/code/axiomatization/datasets/mathlib4_states_w_proof/'\n",
    "# file_names = os.listdir(data_folder)\n",
    "\n",
    "# fout = open('/home/mcwave/code/axiomatization/datasets/mathlib4_states_w_proof_hyp_pred.pkl', 'wb')\n",
    "\n",
    "# count = 0\n",
    "# for file_name in file_names:\n",
    "#     if not file_name.endswith(\"pkl\"):\n",
    "#         continue\n",
    "#     count += 1\n",
    "#     data = []\n",
    "#     print(\"Loading\", file_name)\n",
    "#     file_path = os.path.join(data_folder, file_name)\n",
    "#     fin = open(file_path, 'rb')\n",
    "#     while True:\n",
    "#         try:\n",
    "#             pair = pickle.load(fin)\n",
    "#             data.append(pair) #(pair[1][0], pair[1][2][0]))\n",
    "#         except:\n",
    "#             break\n",
    "#     #\n",
    "#     fin.close()\n",
    "#     print(len(data), \"examples loaded\")\n",
    "#     hyp_data = []\n",
    "#     for pair in data:\n",
    "#         state_pp = pair[1][0]\n",
    "#         tactics = pair[1][2]\n",
    "#         if tactics is None or len(tactics) == 0:\n",
    "#             continue\n",
    "#         full_path = pair[0][2]\n",
    "#         theorem_name = pair[0][3]\n",
    "#         premise, useful_hypotheses = create_hypothesis_predict_data(state_pp, tactics, theorem_name)\n",
    "#         if len(useful_hypotheses) == 0:\n",
    "#             continue\n",
    "#         premise.full_path = full_path\n",
    "#         hyp_data.append((premise, useful_hypotheses))\n",
    "#         pickle.dump((premise, useful_hypotheses), fout)\n",
    "#     #\n",
    "#     fout.flush()\n",
    "#     print(len(hyp_data), \"hypotheses data found\")\n",
    "\n",
    "# fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f161aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "data = []\n",
    "fin = open('/home/mcwave/code/axiomatization/datasets/mathlib4_algebra_states_w_proof_hyp_pred.pkl', 'rb')\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        premise, hypotheses = pickle.load(fin)\n",
    "        state_pp = premise.to_theorem_code()\n",
    "        target_hyp = str([x[1] for x in hypotheses])\n",
    "        data.append((state_pp, target_hyp))\n",
    "    except:\n",
    "        break\n",
    "    \n",
    "fin.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ac695da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/mcwave/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/home/mcwave/anaconda3/envs/atp/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(384, 1472)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(384, 1472)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=1472, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1472, out_features=3584, bias=False)\n",
       "              (wi_1): Linear(in_features=1472, out_features=3584, bias=False)\n",
       "              (wo): Linear(in_features=3584, out_features=1472, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=1472, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1472, out_features=3584, bias=False)\n",
       "              (wi_1): Linear(in_features=1472, out_features=3584, bias=False)\n",
       "              (wo): Linear(in_features=3584, out_features=1472, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(384, 1472)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=1472, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=1472, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1472, out_features=3584, bias=False)\n",
       "              (wi_1): Linear(in_features=1472, out_features=3584, bias=False)\n",
       "              (wo): Linear(in_features=3584, out_features=1472, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-3): 3 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=1472, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=1472, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1472, out_features=3584, bias=False)\n",
       "              (wi_1): Linear(in_features=1472, out_features=3584, bias=False)\n",
       "              (wo): Linear(in_features=3584, out_features=1472, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1472, out_features=384, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AdamW\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "class InstructionResponseDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=512):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        instruction, response = self.data[idx]\n",
    "        \n",
    "        input_encoding = self.tokenizer(instruction, max_length=self.max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "        output_encoding = self.tokenizer(response, max_length=self.max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "        input_mask = input_encoding[\"attention_mask\"].squeeze()\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_encoding[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": input_mask,\n",
    "            \"labels\": output_encoding[\"input_ids\"].squeeze()\n",
    "        }\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "model_name = \"google/byt5-small\"  # You can change this to any other Seq2Seq model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"kaiyuy/leandojo-lean4-tacgen-byt5-small\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "# Create full dataset\n",
    "full_dataset = InstructionResponseDataset(data, tokenizer)\n",
    "\n",
    "# Split into train and test sets\n",
    "train_size = int(0.99 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=20, shuffle=False)\n",
    "\n",
    "# Set up optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Training loop\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7688af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4:   7%|█████████▏                                                                                                                                | 9999/150664 [3:49:47<54:04:35,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4, steps 10000\n",
      "Average Train Loss: 0.0322\n",
      "Average Test Loss: 0.0192\n",
      "[2024-08-16 16:08:48,343] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcwave/anaconda3/envs/atp/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.1.0), only 1.0.0 is known to be compatible\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4:  13%|██████████████████▏                                                                                                                      | 19999/150664 [7:43:53<48:09:51,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4, steps 20000\n",
      "Average Train Loss: 0.0327\n",
      "Average Test Loss: 0.0055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4:  16%|██████████████████████▏                                                                                                                  | 24432/150664 [9:34:16<46:22:40,  1.32s/it]"
     ]
    }
   ],
   "source": [
    "num_epochs = 4\n",
    "eval_steps = 10000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    num_steps = 0\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        num_steps += 1\n",
    "        if num_steps > 0 and num_steps % eval_steps == 0:\n",
    "            avg_train_loss = total_loss / len(train_dataloader)\n",
    "            avg_test_loss = evaluate(model, test_dataloader, device)\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}, steps {num_steps}\")\n",
    "            print(f\"Average Train Loss: {avg_train_loss:.4f}\")\n",
    "            print(f\"Average Test Loss: {avg_test_loss:.4f}\")\n",
    "            # Save the model after each epoch\n",
    "            save_path = f\"/home/mcwave/code/axiomatization/datasets/hyp_pred_byt5_small/trained_model_epoch_{epoch + 1}_steps_{num_steps}\"\n",
    "            os.makedirs(save_path, exist_ok=True)\n",
    "            model.save_pretrained(save_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0915994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34fadb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "state_pps = []\n",
    "target_hyps = []\n",
    "fin = open('/home/mcwave/code/axiomatization/datasets/mathlib4_states_w_proof_hyp_pred.pkl', 'rb')\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        premise, hypotheses = pickle.load(fin)\n",
    "        state_pp = premise.to_theorem_code()\n",
    "        target_hyp = str([x[1] for x in hypotheses])\n",
    "        #data.append((state_pp, target_hyp))\n",
    "        state_pps.append(state_pp)\n",
    "        target_hyps.append(target_hyp)\n",
    "    except:\n",
    "        break\n",
    "    \n",
    "fin.close()\n",
    "\n",
    "ds = Dataset.from_dict({'state_pp': state_pps, 'target_hyp':target_hyps})\n",
    "tmp = ds.train_test_split(test_size=0.01)\n",
    "raw_train_dataset = tmp['train']\n",
    "raw_test_dataset = tmp['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "920ae58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['state_pp', 'target_hyp'],\n",
       "    num_rows: 30438\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4e56826",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping test dataset ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e25d1f04f84feca09cd6eaa901e2f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing dataset:   0%|          | 0/30438 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping train dataset ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a49718c7e2457789f89b8cd32978e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing dataset (num_proc=6):   0%|          | 0/3013264 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# from torch.utils.data import Dataset as TorchDataset, DataLoader, random_split\n",
    "# from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AdamW\n",
    "# from tqdm import tqdm\n",
    "# import os\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"kaiyuy/leandojo-lean4-tacgen-byt5-small\")\n",
    "\n",
    "# def tokenize_function(example):\n",
    "#     instruction = example['state_pp']\n",
    "#     response = example['target_hyp']\n",
    "\n",
    "#     # Tokenize the instruction and response separately\n",
    "#     instruction_tokens = tokenizer(instruction, padding=\"max_length\", truncation=True, max_length=512)\n",
    "#     response_tokens = tokenizer(response, padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "#     # Combine the instruction and response into a single input\n",
    "#     input_ids = instruction_tokens['input_ids']\n",
    "\n",
    "#     # The labels are the same as the input_ids for causal language modeling\n",
    "#     labels = response_tokens['input_ids']\n",
    "\n",
    "#     return {'input_ids': input_ids, 'labels': labels}\n",
    "\n",
    "# print(\"Mapping test dataset ...\")\n",
    "# tokenized_test = raw_test_dataset.map(tokenize_function, batched=True, num_proc=1, desc=\"Tokenizing dataset\")\n",
    "# print(\"Mapping train dataset ...\")\n",
    "# tokenized_train = raw_train_dataset.map(tokenize_function, batched=True, num_proc=6, desc=\"Tokenizing dataset\")\n",
    "# print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa6f55e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate(model, dataloader, device):\n",
    "#     model.eval()\n",
    "#     total_loss = 0\n",
    "#     with torch.no_grad():\n",
    "#         for batch in dataloader:\n",
    "#             input_ids = batch[\"input_ids\"].to(device)\n",
    "#             attention_mask = batch[\"attention_mask\"].to(device)\n",
    "#             labels = batch[\"labels\"].to(device)\n",
    "\n",
    "#             outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "#             loss = outputs.loss\n",
    "#             total_loss += loss.item()\n",
    "\n",
    "#     return total_loss / len(dataloader)\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "model_name = \"google/byt5-small\"  # You can change this to any other Seq2Seq model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Set up optimizer\n",
    "#optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Training loop\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e1cbf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcwave/anaconda3/envs/atp/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3001' max='1004424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   3001/1004424 32:11 < 179:12:08, 1.55 it/s, Epoch 0.01/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='328' max='2537' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 328/2537 00:43 < 04:55, 7.46 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import load_dataset,load_metric\n",
    "from transformers import AutoTokenizer, DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"datasets/byt5-small\",\n",
    "    evaluation_strategy=\"steps\", #\"epochs\"\n",
    "    learning_rate=2e-5,  # PAY ATTENTION TO LEARNING RATE!\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=12,\n",
    "    per_device_eval_batch_size=12,\n",
    "    num_train_epochs=4,\n",
    "    fp16=False,\n",
    "    save_steps=1000,\n",
    "    eval_steps=1000,\n",
    "    logging_steps=1000,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "#cp_path = 'gpt-neo-350m-202310/checkpoint-525000'\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dff0cc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4:  36%|███████████████████████████▌                                                 | 106651/298283 [21:38:44<38:53:35,  1.37it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(train_dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m----> 7\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m     labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# num_epochs = 4\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "\n",
    "#     for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "#         input_ids = batch[\"input_ids\"].to(device)\n",
    "#         attention_mask = batch[\"attention_mask\"].to(device)\n",
    "#         labels = batch[\"labels\"].to(device)\n",
    "\n",
    "#         outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "#         loss = outputs.loss\n",
    "#         total_loss += loss.item()\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "    \n",
    "#     # Save the model after each epoch\n",
    "#     save_path = f\"/home/mcwave/code/axiomatization/datasets/hyp_pred_byt5_small/trained_model_epoch_{epoch + 1}\"\n",
    "#     os.makedirs(save_path, exist_ok=True)\n",
    "#     model.save_pretrained(save_path)\n",
    "    \n",
    "#     avg_train_loss = total_loss / len(train_dataloader)\n",
    "#     avg_test_loss = evaluate(model, test_dataloader, device)\n",
    "\n",
    "#     print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "#     print(f\"Average Train Loss: {avg_train_loss:.4f}\")\n",
    "#     print(f\"Average Test Loss: {avg_test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "485a6b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_test_loss = evaluate(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5dcdf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mcwave/code/axiomatization/datasets/hyp_pred_byt5_small/trained_model_epoch_1\n"
     ]
    }
   ],
   "source": [
    "# save_path = f\"/home/mcwave/code/axiomatization/datasets/hyp_pred_byt5_small/trained_model_epoch_{epoch + 1}\"\n",
    "# print(save_path)\n",
    "# os.makedirs(save_path, exist_ok=True)\n",
    "# model.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c30c15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = f\"/home/mcwave/code/axiomatization/datasets/hyp_pred_byt5_small/trained_model_epoch_1\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f8e070b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: theorem Function.Exact.apply_apply_eq_zero (R: Type u_1) (M: Type u_2) (M': Type u_3) (N: Type u_4) (N': Type u_5) (P: Type u_6) (P': Type u_7) (f: M → N) (g: N → P) (inst✝: Zero P) (x: M) : ¬¬¬¬¬Exact f g :=\n",
      "labels: ['¬¬¬¬¬g (f x) = 0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcwave/anaconda3/envs/atp/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated: _ (S__u_7)) (G) (R\n",
      "True: ['¬¬¬¬¬g (f x) = 0']\n"
     ]
    }
   ],
   "source": [
    "test_case = tokenized_test[7]\n",
    "input_ids = torch.tensor(test_case['input_ids']).unsqueeze(0).to('cuda')  # Add batch dimension\n",
    "print(\"inputs:\", tokenizer.decode(test_case['input_ids'], skip_special_tokens=True))\n",
    "labels = torch.tensor(test_case['labels']).to('cuda')\n",
    "print(\"labels:\", tokenizer.decode(labels, skip_special_tokens=True))\n",
    "\n",
    "# Generate output\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(input_ids)\n",
    "\n",
    "# Decode the generated output and the true labels\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "true_text = tokenizer.decode(labels, skip_special_tokens=True)\n",
    "\n",
    "# Compare the results\n",
    "print(\"Generated:\", generated_text)\n",
    "print(\"True:\", true_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfc295d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([94, 42, 74, 42, 96,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atp",
   "language": "python",
   "name": "atp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
