{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b32bc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Mathlib__Algebra__Ring__Subring__Pointwise.lean.pkl\n",
      "12680 examples loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "data_folder = '/home/mcwave/code/automath/atp/datasets/provability/mathlib4_states_w_proof/'\n",
    "file_names = os.listdir(data_folder)\n",
    "\n",
    "data = []\n",
    "\n",
    "count = 0\n",
    "for file_name in file_names:\n",
    "    if not file_name.endswith(\"pkl\"):\n",
    "        continue\n",
    "    if not 'Algebra' in file_name:\n",
    "        continue\n",
    "    count += 1\n",
    "    if count <= 5:\n",
    "        continue\n",
    "    print(\"Loading\", file_name)\n",
    "    file_path = os.path.join(data_folder, file_name)\n",
    "    fin = open(file_path, 'rb')\n",
    "    while True:\n",
    "        try:\n",
    "            pair = pickle.load(fin)\n",
    "            data.append(pair) #(pair[1][0], pair[1][2][0]))\n",
    "        except:\n",
    "            break\n",
    "    break\n",
    "\n",
    "print(len(data), \"examples loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "782ea1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATE_PP:\n",
      "case h\n",
      "M : Type u_1\n",
      "R : Type u_2\n",
      "inst‚úù¬≤ : Monoid M\n",
      "inst‚úù¬π : Ring R\n",
      "inst‚úù : MulSemiringAction M R\n",
      "a : M\n",
      "S : Subring R\n",
      "nvar0 : R\n",
      "‚ä¢ nvar0 ‚àà map (MulSemiringAction.toRingHom M R a) S ‚Üî nvar0 ‚àà a ‚Ä¢ S\n",
      "TACTICS:\n",
      "symm\n",
      "simp [eq_comm (a := a)]\n",
      "cases S\n",
      "rw [smul_neg]\n",
      "rw [‚Üê eq_f‚ÇÄ']\n",
      "STATE_PP:\n",
      "theorem Subring.pointwise_smul_def (M: Type u_1) (R: Type u_2) (inst‚úù¬≤: Monoid M) (inst‚úù¬π: Ring R) (inst‚úù: MulSemiringAction M R) (a: M) (S: Subring R) (nvar0: R) : nvar0 ‚àà map (MulSemiringAction.toRingHom M R a) S ‚Üî nvar0 ‚àà a ‚Ä¢ S :=\n",
      "\n",
      "HYPOTHESES:\n",
      " []\n"
     ]
    }
   ],
   "source": [
    "from utils.lean_math_utils import *\n",
    "from utils.lean_theorem_utils import *\n",
    "\n",
    "def count_lines(string):\n",
    "    # Split the string into lines\n",
    "    lines = string.splitlines()\n",
    "    # Count the number of lines\n",
    "    return len(lines)\n",
    "\n",
    "def extract_first_case(state_pp):\n",
    "    state_pp = state_pp.strip()\n",
    "    if not state_pp.startswith('case'):\n",
    "        return state_pp\n",
    "    lines = state_pp.split('\\n')\n",
    "    first_case = []\n",
    "    for line in lines[1:]:\n",
    "        if line.strip().startswith('case'):\n",
    "            break\n",
    "        if line.strip() != '':\n",
    "            first_case.append(line)\n",
    "    return '\\n'.join(first_case)\n",
    "\n",
    "\n",
    "# Params:\n",
    "#   hyp: tuple(name, type)\n",
    "#   tactics: list(tactic)\n",
    "def is_hypothesis_useful(hyp, tactics):\n",
    "    for tactic in tactics:\n",
    "        tokens = tokenize_lean_tactic(tactic)\n",
    "        if hyp[0] in tokens:\n",
    "            idx = tokens.index(hyp[0])\n",
    "            if idx > 0:\n",
    "                if hyp[0].startswith('h'):\n",
    "                    return True\n",
    "                if tokens[idx - 1] == 'exact':\n",
    "                    return True\n",
    "                if tokens[idx - 1] == 'at':\n",
    "                    return True\n",
    "                if tokens[idx - 1] == '[':\n",
    "                    return True\n",
    "                if idx < len(tokens) - 1 and tokens[idx + 1] == ']':\n",
    "                    return True\n",
    "                for operator in TargetNode.operators:\n",
    "                    if operator in hyp[1]:\n",
    "                        return True\n",
    "    return False\n",
    "\n",
    "def create_hypothesis_predict_data(raw_state_pp, tactics, theorem_name):\n",
    "    is_case = raw_state_pp.strip().startswith('case')\n",
    "    state_pp = extract_first_case(raw_state_pp)\n",
    "    if is_case and count_lines(state_pp) < count_lines(raw_state_pp) - 2:\n",
    "        tactics = tactics[0:1]\n",
    "    #\n",
    "    premise = Premise()\n",
    "    premise.theorem_name = theorem_name\n",
    "    premise.parse_state(state_pp)\n",
    "    #\n",
    "    useful_hypotheses, useless_hypotheses = [], OrderedDict()\n",
    "    for hyp in premise.hypotheses.items():\n",
    "        useful = is_hypothesis_useful(hyp, tactics)\n",
    "        if useful:\n",
    "            #print(\"YES:\", hyp)\n",
    "            useful_hypotheses.append(hyp)\n",
    "        else:\n",
    "            #print(\"NO :\", hyp)\n",
    "            useless_hypotheses[hyp[0]] = hyp[1]\n",
    "    premise.hypotheses = useless_hypotheses\n",
    "    return premise, useful_hypotheses\n",
    "\n",
    "idx = 120\n",
    "\n",
    "state_pp = data[idx][1][0]\n",
    "tactics = data[idx][1][2]\n",
    "theorem_name = data[idx][0][3]\n",
    "\n",
    "print(\"STATE_PP:\\n\" + state_pp)\n",
    "\n",
    "print(\"TACTICS:\\n\" + \"\\n\".join(tactics))\n",
    "\n",
    "premise, useful_hypotheses = create_hypothesis_predict_data(state_pp, tactics, theorem_name)\n",
    "\n",
    "print(\"STATE_PP:\\n\" + premise.to_theorem_code())\n",
    "print(\"\\nHYPOTHESES:\\n\", useful_hypotheses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34fadb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 3396064\n",
      "Test: 24237\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "MIN_LENGTH = 4\n",
    "\n",
    "TEST_MOD = 130\n",
    "\n",
    "train_state_pps = []\n",
    "test_state_pps = []\n",
    "train_target_hyps = []\n",
    "test_target_hyps = []\n",
    "seen_hashes = set()\n",
    "fin = open('/home/mcwave/code/axiomatization/datasets/mathlib4_all_states_w_proof_hyp_pred.pkl', 'rb')\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        premise, hypotheses = pickle.load(fin)\n",
    "        state_pp = premise.to_theorem_code()\n",
    "        target_hyp = str([x[1] for x in hypotheses])\n",
    "        hash_value = hash(state_pp + '|' + target_hyp)\n",
    "        if hash_value in seen_hashes:\n",
    "            continue\n",
    "        else:\n",
    "            seen_hashes.add(hash_value)\n",
    "        #data.append((state_pp, target_hyp))\n",
    "        if len(state_pp) < 4 or len(target_hyp) < 4:\n",
    "            continue\n",
    "        if hash(premise.theorem_name) % TEST_MOD == 0:\n",
    "            test_state_pps.append(state_pp)\n",
    "            test_target_hyps.append(target_hyp)\n",
    "        else:\n",
    "            train_state_pps.append(state_pp)\n",
    "            train_target_hyps.append(target_hyp)\n",
    "    except:\n",
    "        break\n",
    "    \n",
    "fin.close()\n",
    "\n",
    "print(\"Train:\", len(train_state_pps))\n",
    "print(\"Test:\", len(test_state_pps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eb771e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset, Dataset, load_from_disk\n",
    "\n",
    "MAX_LENGTH = 300\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "\n",
    "model_name = \"morph-labs/morph-prover-v0-7b\" #\"internlm/internlm2-math-7b\" #\"ScalableMath/Lean-STaR-plus\"  # 'Saisam/gpt-neo-math-small' #\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "# Define the separator token\n",
    "sep_token = \"<sep>\"\n",
    "pad_token = \"<pad>\"\n",
    "\n",
    "# Check if the separator token already exists in the vocabulary\n",
    "if sep_token not in tokenizer.get_vocab():\n",
    "    tokenizer.add_tokens([sep_token])\n",
    "if pad_token not in tokenizer.get_vocab():\n",
    "    tokenizer.add_tokens([pad_token])\n",
    "\n",
    "# Set the separator token\n",
    "tokenizer.sep_token = sep_token\n",
    "tokenizer.pad_token = pad_token\n",
    "\n",
    "tokenizer.add_special_tokens({\n",
    "    'sep_token': sep_token,\n",
    "    'pad_token': pad_token\n",
    "})\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"datasets/text_for_tokenization/mathlib4_20240617_bpe_tokenizer\")\n",
    "# # Define the tokens\n",
    "# sep_token = \"<sep>\"\n",
    "# pad_token = \"<pad>\"\n",
    "\n",
    "# # Set the sep_token and pad_token\n",
    "# tokenizer.sep_token = sep_token\n",
    "# tokenizer.pad_token = pad_token\n",
    "# #tokenizer.add_special_tokens({'sep_token': '[SEP]'})\n",
    "\n",
    "\n",
    "# Function to tokenize and prepare the data\n",
    "def prepare_data(examples):\n",
    "    # Concatenate instruction and response with a separator\n",
    "    full_texts = [f\"{instruction} <sep> {response}\" for instruction, response in zip(examples['instruction'], examples['response'])]\n",
    "    \n",
    "    # Tokenize the full texts\n",
    "    encodings = tokenizer(full_texts, truncation=True, padding='max_length', max_length=MAX_LENGTH, return_tensors='pt')\n",
    "    #print(encodings)\n",
    "    \n",
    "    # Create attention masks: 1 for response tokens, 0 for instruction tokens and padding\n",
    "    attention_masks = []\n",
    "    labels = []\n",
    "    \n",
    "    for input_ids in encodings['input_ids']:\n",
    "        attention_mask = torch.zeros_like(input_ids)\n",
    "        label = input_ids.clone()\n",
    "        \n",
    "        pad_token_idx = (input_ids == tokenizer.pad_token_id).nonzero()\n",
    "        end_idx = pad_token_idx[0].item() if len(pad_token_idx) > 0 else len(input_ids)\n",
    "        sep_token_idx = (input_ids == tokenizer.sep_token_id).nonzero()\n",
    "        #print(\"sep_token_idx:\", sep_token_idx)\n",
    "        if len(sep_token_idx) == 0:\n",
    "            sep_token_idx = 0\n",
    "        else:\n",
    "            sep_token_idx = sep_token_idx.item()\n",
    "\n",
    "        attention_mask[0:end_idx] = 1\n",
    "        attention_masks.append(attention_mask)\n",
    "        \n",
    "        label[0:sep_token_idx+1] = -100\n",
    "        labels.append(label)\n",
    "    \n",
    "    return {\n",
    "        'input_ids': encodings['input_ids'],\n",
    "        'attention_mask': torch.stack(attention_masks),\n",
    "        'labels': torch.stack(labels)\n",
    "    }\n",
    "\n",
    "# # Create the Hugging Face dataset\n",
    "# test_dataset = Dataset.from_dict({\n",
    "#     'instruction': test_state_pps,\n",
    "#     'response': test_target_hyps\n",
    "# }).shuffle(seed=42)\n",
    "\n",
    "# # Apply the tokenization and preparation function\n",
    "# tokenized_test = test_dataset.map(\n",
    "#     prepare_data,\n",
    "#     batched=True,\n",
    "#     num_proc=4\n",
    "#     #remove_columns=dataset.column_names\n",
    "# )\n",
    "\n",
    "# # Create the Hugging Face dataset\n",
    "# train_dataset = Dataset.from_dict({\n",
    "#     'instruction': train_state_pps,\n",
    "#     'response': train_target_hyps\n",
    "# }).shuffle(seed=42)\n",
    "\n",
    "# # Apply the tokenization and preparation function\n",
    "# tokenized_train = train_dataset.map(\n",
    "#     prepare_data,\n",
    "#     batched=True,\n",
    "#     num_proc=4\n",
    "#     #remove_columns=dataset.column_names\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "920ae58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c63a659a8141d1b067fff86eb5933d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset, Dataset, load_from_disk\n",
    "\n",
    "#tokenized_train.save_to_disk('datasets/predict_hyp_tokenized_train.dataset')\n",
    "#tokenized_test.save_to_disk('datasets/predict_hyp_tokenized_test.dataset')\n",
    "\n",
    "tokenized_train = load_from_disk('datasets/predict_hyp_tokenized_train.dataset')\n",
    "tokenized_test = load_from_disk('datasets/predict_hyp_tokenized_test.dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68be9067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8258b9cd601540679ed2f082133eafcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2daec8fd3f14dbe954351f361cd00c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f9f20ee8ac44ffe8b11d16b70929333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/138 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Embedding(32002, 1536)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "#from huggingface_hub import login\n",
    "\n",
    "#login(token=\"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\")\n",
    "\n",
    "model_name = \"Qwen/Qwen2-1.5B\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e1cbf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcwave/anaconda3/envs/axiom/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='65793' max='1132024' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  65793/1132024 13:30:20 < 218:52:44, 1.35 it/s, Epoch 0.23/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.347700</td>\n",
       "      <td>0.408780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.199400</td>\n",
       "      <td>0.376625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.171800</td>\n",
       "      <td>0.359299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import load_dataset,load_metric\n",
    "from transformers import AutoTokenizer, DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"datasets/predict-hyp-qwen-1.5b\",\n",
    "    evaluation_strategy=\"steps\", #\"epochs\"\n",
    "    learning_rate=1e-5,  # PAY ATTENTION TO LEARNING RATE!\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=12,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=4,\n",
    "    bf16=True,\n",
    "    max_grad_norm=1.0,\n",
    "    save_steps=20000,\n",
    "    eval_steps=20000,\n",
    "    logging_steps=20000,\n",
    "    save_total_limit=3,\n",
    "    #load_best_model_at_end=True,\n",
    "    push_to_hub=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "cp_path = 'datasets/predict-hyp-gemma-2b-v0/checkpoint-200000'\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f642f4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s> theorem LinearMap.exact_map_mkQ_range (R: Type u_1) (M: Type u_2) (N: Type u_3) (P: Type u_4) (inst‚úù‚Å∂: CommRing R) (inst‚úù‚Åµ: AddCommGroup M) (inst‚úù‚Å¥: AddCommGroup N) (inst‚úù¬≥: AddCommGroup P) (inst‚úù¬≤: Module R M) (inst‚úù¬π: Module R N) (inst‚úù: Module R P) (y‚úù: N) : y‚úù ‚àà Set.range ‚áëf ‚Üî 0 = (range f).mkQ y‚úù := <sep>  ['M ‚Üí‚Çó[R] N']<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_test[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "458582ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CASE 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: theorem LinearMap.exact_map_mkQ_range (R: Type u_1) (M: Type u_2) (N: Type u_3) (P: Type u_4) (inst‚úù‚Å∂: CommRing R) (inst‚úù‚Åµ: AddCommGroup M) (inst‚úù‚Å¥: AddCommGroup N) (inst‚úù¬≥: AddCommGroup P) (inst‚úù¬≤: Module R M) (inst‚úù¬π: Module R N) (inst‚úù: Module R P) (y‚úù: N) : y‚úù ‚àà Set.range ‚áëf ‚Üî 0 = (range f).mkQ y‚úù :=\n",
      "labels:  ['M ‚Üí‚Çó[R] N']\n",
      "Generated: theorem LinearMap.exact_map_mkQ_range (R: Type u_1) (M: Type u_2) (N: Type u_3) (P: Type u_4) (inst‚úù‚Å∂: CommRing R) (inst‚úù‚Åµ: AddCommGroup M) (inst‚úù‚Å¥: AddCommGroup N) (inst‚úù¬≥: AddCommGroup P) (inst‚úù¬≤: Module R M) (inst‚úù¬π: Module R N) (inst‚úù: Module R P) (y‚úù: N) : y‚úù ‚àà Set.range ‚áëf ‚Üî 0 = (range f).mkQ y‚úù :=   ['M ‚Üí‚Çó[R] N ‚Üí‚Çó[R] P']']']']']']']']']'].range']']']']']']']']']']'].range']']']']\n",
      "\n",
      "CASE 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: theorem AdjoinRoot.smul_mk (R: Type u) (S: Type v) (K: Type w) (inst‚úù¬≤: CommRing R) (inst‚úù¬π: DistribSMul S R) (inst‚úù: IsScalarTower S R R) (a x ‚ä¢ Quotient.map' (fun => ‚Ä¢ x) ‚ãØ ((mk {: = toFinsupp‚úù }) x) = (mk { toFinsupp := toFinsupp‚úù }) (a ‚Ä¢ x)) (toFinsupp‚úù: AddMonoidAlgebra R ‚Ñï) :  :=\n",
      "labels:  ['= toFinsupp‚úù }) x) = (mk { toFinsupp := toFinsupp‚úù }) (a ‚Ä¢ x)']\n",
      "Generated: theorem AdjoinRoot.smul_mk (R: Type u) (S: Type v) (K: Type w) (inst‚úù¬≤: CommRing R) (inst‚úù¬π: DistribSMul S R) (inst‚úù: IsScalarTower S R R) (a x ‚ä¢ Quotient.map' (fun => ‚Ä¢ x) ‚ãØ ((mk {: = toFinsupp‚úù }) x) = (mk { toFinsupp := toFinsupp‚úù }) (a ‚Ä¢ x)) (toFinsupp‚úù: AddMonoidAlgebra R ‚Ñï) :  :=   ['= toFinsupp‚úù }) x) = (mk { toFinsupp := toFinsupp‚úù }) (a ‚Ä¢ x)']']']']']']']']']']']']']\n",
      "\n",
      "CASE 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: theorem Finset.diffs_union_right (F: Type u_1) (Œ±: Type u_2) (Œ≤: Type u_3) (inst‚úù¬≤: DecidableEq Œ±) (inst‚úù¬π: DecidableEq Œ≤) (inst‚úù: GeneralizedBooleanAlgebra Œ±) (s‚ÇÅ s‚ÇÇ t t‚ÇÅ t‚ÇÇ u v: Finset Œ±) (a b c: Œ±) (val‚úù: Multiset Œ±) (nodup‚úù: val‚úù.Nodup) (‚ä¢: = val‚úù, nodup := nodup‚úù } \\\\ (t‚ÇÅ ‚à™ t‚ÇÇ \\ t‚ÇÅ) =) ({: = val‚úù, nodup := nodup‚úù } \\\\ t‚ÇÅ ‚à™ { val := val‚úù, nodup := nodup‚úù } \\\\ t‚ÇÇ) :  :=\n",
      "labels:  ['= val‚úù, nodup := nodup‚úù } \\\\\\\\ t‚ÇÅ ‚à™ { val := val‚úù, nodup := nodup‚úù } \\\\\\\\ t‚ÇÇ']\n",
      "Generated: theorem Finset.diffs_union_right (F: Type u_1) (Œ±: Type u_2) (Œ≤: Type u_3) (inst‚úù¬≤: DecidableEq Œ±) (inst‚úù¬π: DecidableEq Œ≤) (inst‚úù: GeneralizedBooleanAlgebra Œ±) (s‚ÇÅ s‚ÇÇ t t‚ÇÅ t‚ÇÇ u v: Finset Œ±) (a b c: Œ±) (val‚úù: Multiset Œ±) (nodup‚úù: val‚úù.Nodup) (‚ä¢: = val‚úù, nodup := nodup‚úù } \\\\ (t‚ÇÅ ‚à™ t‚ÇÇ \\ t‚ÇÅ) =) ({: = val‚úù, nodup := nodup‚úù } \\\\ t‚ÇÅ ‚à™ { val := val‚úù, nodup := nodup‚úù } \\\\ t‚ÇÇ) :  :=   ['= val‚úù, nodup := nodup‚úù } \\\\\\\\ t‚ÇÅ ‚à™ { val := val‚úù, nodup := nodup‚úù } \\\\\\\\ t‚ÇÇ']',\n",
      "\n",
      "CASE 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: theorem RootPairing.coreflection_eq_flip_reflection (Œπ: Type u_1) (R: Type u_2) (M: Type u_3) (N: Type u_4) (inst‚úù‚Å¥: CommRing R) (inst‚úù¬≥: AddCommGroup M) (inst‚úù¬≤: Module R M) (inst‚úù¬π: AddCommGroup N) (inst‚úù: Module R N) (i j: Œπ) (f: N) (toPerfectPairing‚úù: PerfectPairing R M N) (root‚úù: Œπ ‚Ü™ M) (coroot‚úù: Œπ ‚Ü™ N) (root_coroot_two‚úù: ‚àÄ (i : Œπ), (toPerfectPairing‚úù.toLin (root‚úù i)) (coroot‚úù i) = 2) (mapsTo_preReflection_root‚úù mapsTo_preReflection_coroot‚úù: ) ((i: Œπ), MapsTo (‚áë(preReflection (coroot‚úù i) (toPerfectPairing‚úù.toLin (root‚úù i)))) (range ‚áëcoroot‚úù) (range ‚áëcoroot‚úù)) (-(({ ({: = toPerfectPairing‚úù, root := root‚úù, coroot := coroot‚úù, root_coroot_two := root_coroot_two‚úù,) (mapsTo_preReflection_root: = mapsTo_preReflection_root‚úù,) (root_coroot_two: = root_coroot_two‚úù, mapsTo_preReflection_root := mapsTo_preReflection_root‚úù,) ({: = toPerfectPairing‚úù, root := root‚úù, coroot := coroot‚úù,) : f + :=\n",
      "labels: theorem RootPairing.coreflection_eq_flip_reflection (Œπ: Type u_1) (R: Type u_2) (M: Type u_3) (N: Type u_4) (inst‚úù‚Å¥: CommRing R) (inst‚úù¬≥: AddCommGroup M) (inst‚úù¬≤: Module R M) (inst‚úù¬π: AddCommGroup N) (inst‚úù: Module R N) (i j: Œπ) (f: N) (toPerfectPairing‚úù: PerfectPairing R M N) (root‚úù: Œπ ‚Ü™ M) (coroot‚úù: Œπ ‚Ü™ N) (root_coroot_two‚úù: ‚àÄ (i : Œπ), (toPerfectPairing‚úù.toLin (root‚úù i)) (coroot‚úù i) = 2) (mapsTo_preReflection_root‚úù mapsTo_preReflection_coroot‚úù: ) ((i: Œπ), MapsTo (‚áë(preReflection (coroot‚úù i) (toPerfectPairing‚úù.toLin (root‚úù i)))) (range ‚áëcoroot‚úù) (range \n",
      "Generated: theorem RootPairing.coreflection_eq_flip_reflection (Œπ: Type u_1) (R: Type u_2) (M: Type u_3) (N: Type u_4) (inst‚úù‚Å¥: CommRing R) (inst‚úù¬≥: AddCommGroup M) (inst‚úù¬≤: Module R M) (inst‚úù¬π: AddCommGroup N) (inst‚úù: Module R N) (i j: Œπ) (f: N) (toPerfectPairing‚úù: PerfectPairing R M N) (root‚úù: Œπ ‚Ü™ M) (coroot‚úù: Œπ ‚Ü™ N) (root_coroot_two‚úù: ‚àÄ (i : Œπ), (toPerfectPairing‚úù.toLin (root‚úù i)) (coroot‚úù i) = 2) (mapsTo_preReflection_root‚úù mapsTo_preReflection_coroot‚úù: ) ((i: Œπ), MapsTo (‚áë(preReflection (coroot‚úù i) (toPerfectPairing‚úù.toLin (root‚úù i)))) (range ‚áëcoroot‚úù) (range ‚áëcoroot‚úù)) (-(({ ({: = toPerfectPairing‚úù, root := root‚úù, coroot := coroot‚úù, root_coroot_two := root_coroot_two‚úù,) (mapsTo_preReflection_root: = mapsTo_preReflection_root‚úù,) (root_coroot_two: = root_coroot_two‚úù, mapsTo_preReflection_root := mapsTo_preReflection_root‚úù,) ({: = toPerfectPairing‚úù, root := root‚úù, coroot := coroot‚úù,) : f + :=   ['Œπ), MapsTo (‚áë(preReflection (coroot‚úù i) (toPerfectPairing‚úù.toLin (root‚úù i)))) (range ‚áëcor\n",
      "\n",
      "CASE 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: theorem Finsupp.prod_ne_zero_iff (Œ±: Type u_1) (Œπ: Type u_2) (Œ≥: Type u_3) (A: Type u_4) (B: Type u_5) (C: Type u_6) (inst‚úù‚Å∂: AddCommMonoid A) (inst‚úù‚Åµ: AddCommMonoid B) (inst‚úù‚Å¥: AddCommMonoid C) (t: Œπ ‚Üí A ‚Üí C) (h0: ‚àÄ (i : Œπ), t i 0 = 0) (h1: ‚àÄ (i : Œπ) (x y : A), t i (x + y) = t i x + t i y) (s: Finset Œ±) (f‚úù: Œ± ‚Üí Œπ ‚Üí‚ÇÄ A) (i: Œπ) (g‚úù: Œπ ‚Üí‚ÇÄ A) (k: Œπ ‚Üí A ‚Üí Œ≥ ‚Üí B) (x: Œ≥) (Œ≤: Type u_7) (M: Type u_8) (M': Type u_9) (N: Type u_10) (P: Type u_11) (G: Type u_12) (R: Type u_14) (S: Type u_15) (inst‚úù¬≥: Zero Œ±) (inst‚úù¬≤: CommMonoidWithZero Œ≤) (inst‚úù¬π: Nontrivial Œ≤) (inst‚úù: NoZeroDivisors Œ≤) (f: Œπ ‚Üí‚ÇÄ Œ±) (a: Œ±) (g: Œπ ‚Üí Œ± ‚Üí Œ≤) (‚ä¢ (‚àÄ (i: Œπ), f i ‚â† 0 ‚Üí g i (f i) ‚â† ?m.111048 * 0) ‚Üî f.prod g ‚â† ?m.111048 * 0) : Œ≤ :=\n",
      "labels: theorem Finsupp.prod_ne_zero_iff (Œ±: Type u_1) (Œπ: Type u_2) (Œ≥: Type u_3) (A: Type u_4) (B: Type u_5) (C: Type u_6) (inst‚úù‚Å∂: AddCommMonoid A) (inst‚úù‚Åµ: AddCommMonoid B) (inst‚úù‚Å¥: AddCommMonoid C) (t: Œπ ‚Üí A ‚Üí C) (h0: ‚àÄ (i : Œπ), t i 0 = 0) (h1: ‚àÄ (i : Œπ) (x y : A), t i (x + y) = t i x + t i y) (s: Finset Œ±) (f‚úù: Œ± ‚Üí Œπ ‚Üí‚ÇÄ A) (i: Œπ) (g‚úù: Œπ ‚Üí‚ÇÄ A) (k: Œπ ‚Üí A ‚Üí Œ≥ ‚Üí B) (x: Œ≥) (Œ≤: Type u_7) (M: Type u_8) (M': Type u_9) (N: Type u_10) (P: Type u_11) (G: Type u_12) (R: Type u_14) (S\n",
      "Generated: theorem Finsupp.prod_ne_zero_iff (Œ±: Type u_1) (Œπ: Type u_2) (Œ≥: Type u_3) (A: Type u_4) (B: Type u_5) (C: Type u_6) (inst‚úù‚Å∂: AddCommMonoid A) (inst‚úù‚Åµ: AddCommMonoid B) (inst‚úù‚Å¥: AddCommMonoid C) (t: Œπ ‚Üí A ‚Üí C) (h0: ‚àÄ (i : Œπ), t i 0 = 0) (h1: ‚àÄ (i : Œπ) (x y : A), t i (x + y) = t i x + t i y) (s: Finset Œ±) (f‚úù: Œ± ‚Üí Œπ ‚Üí‚ÇÄ A) (i: Œπ) (g‚úù: Œπ ‚Üí‚ÇÄ A) (k: Œπ ‚Üí A ‚Üí Œ≥ ‚Üí B) (x: Œ≥) (Œ≤: Type u_7) (M: Type u_8) (M': Type u_9) (N: Type u_10) (P: Type u_11) (G: Type u_12) (R: Type u_14) (S: Type u_15) (inst‚úù¬≥: Zero Œ±) (inst‚úù¬≤: CommMonoidWithZero Œ≤) (inst‚úù¬π: Nontrivial Œ≤) (inst‚úù: NoZeroDivisors Œ≤) (f: Œπ ‚Üí‚ÇÄ Œ±) (a: Œ±) (g: Œπ ‚Üí Œ± ‚Üí Œ≤) (‚ä¢ (‚àÄ (i: Œπ), f i ‚â† 0 ‚Üí g i (f i) ‚â† ?m.111048 * 0) ‚Üî f.prod g ‚â† ?m.111048 * 0) : Œ≤ :=   ['Type u_10']']']'] f'] g']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']\n",
      "\n",
      "CASE 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: theorem unitInterval.volume_def (nvar0: Set ‚ÜëI) (nvar1: ‚Ñù) : ‚àÉ b, (Measure.comap Subtype.val volume) nvar0 = ‚Üëb ‚àß b ‚â§ ‚ü®nvar1, nvar2‚ü© :=\n",
      "labels:  ['0 ‚â§ nvar1', 'volume nvar0 = ‚Üë‚ü®nvar1, nvar2‚ü©']\n",
      "Generated: theorem unitInterval.volume_def (nvar0: Set ‚ÜëI) (nvar1: ‚Ñù) : ‚àÉ b, (Measure.comap Subtype.val volume) nvar0 = ‚Üëb ‚àß b ‚â§ ‚ü®nvar1, nvar2‚ü© :=   ['0 ‚â§ nvar1'] ‚àß 0 ‚â§ ‚ü®nvar1, nvar2‚ü©']', 'volume nvar0 = ‚Üë‚ü®nvar1, nvar2‚ü©']']\n",
      "\n",
      "CASE 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: theorem interior_sInter_subset (X: Type u) (Y: Type v) (Œπ: Sort w) (Œ±: Type u_1) (Œ≤: Type u_2) (x nvar0: X) (s s‚ÇÅ s‚ÇÇ t: Set X) (p p‚ÇÅ p‚ÇÇ: X ‚Üí Prop) (inst‚úù: TopologicalSpace X) (S: Set (Set X)) : nvar0 ‚àà ‚ãÇ s ‚àà S, ‚ãÉ‚ÇÄ {t | IsOpen t ‚àß t ‚äÜ s} :=\n",
      "labels:  ['nvar0 ‚àà ‚ãÉ‚ÇÄ {t | IsOpen t ‚àß t ‚äÜ ‚ãÇ‚ÇÄ S}']\n",
      "Generated: theorem interior_sInter_subset (X: Type u) (Y: Type v) (Œπ: Sort w) (Œ±: Type u_1) (Œ≤: Type u_2) (x nvar0: X) (s s‚ÇÅ s‚ÇÇ t: Set X) (p p‚ÇÅ p‚ÇÇ: X ‚Üí Prop) (inst‚úù: TopologicalSpace X) (S: Set (Set X)) : nvar0 ‚àà ‚ãÇ s ‚àà S, ‚ãÉ‚ÇÄ {t | IsOpen t ‚àß t ‚äÜ s} :=   ['nvar0 ‚àà ‚ãÇ‚ÇÄ S'] ‚àÄ t ‚àà S, nvar0 ‚àà t'] ‚àß t ‚äÜ ‚ãÇ‚ÇÄ\n",
      "\n",
      "CASE 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: theorem RootPairing.coreflection_eq_flip_reflection (Œπ: Type u_1) (R: Type u_2) (M: Type u_3) (N: Type u_4) (inst: CommRing R) (inst_1: AddCommGroup M) (inst_3: AddCommGroup N) (inst_4: Module R N) (i j: Œπ) (f: N) (root: Œπ ‚Ü™ M) (coroot: Œπ ‚Ü™ N) (root_coroot_two: ‚àÄ (i : Œπ), (toPerfectPairing.toLin (root i)) (coroot i) = 2) (mapsTo_preReflection_root: = mapsTo_preReflection_root,) ((i: Œπ), MapsTo (‚áë(preReflection (coroot i) (toPerfectPairing.toLin (root i)))) (range ‚áëcoroot) (range ‚áëcoroot)) (‚ä¢ ({ {: = toPerfectPairing, root := root, coroot := coroot, root_coroot_two := root_coroot_two,) :  :=\n",
      "labels:  ['Module R M', '= toPerfectPairing, root := root, coroot := coroot,\n",
      "Generated: theorem RootPairing.coreflection_eq_flip_reflection (Œπ: Type u_1) (R: Type u_2) (M: Type u_3) (N: Type u_4) (inst: CommRing R) (inst_1: AddCommGroup M) (inst_3: AddCommGroup N) (inst_4: Module R N) (i j: Œπ) (f: N) (root: Œπ ‚Ü™ M) (coroot: Œπ ‚Ü™ N) (root_coroot_two: ‚àÄ (i : Œπ), (toPerfectPairing.toLin (root i)) (coroot i) = 2) (mapsTo_preReflection_root: = mapsTo_preReflection_root,) ((i: Œπ), MapsTo (‚áë(preReflection (coroot i) (toPerfectPairing.toLin (root i)))) (range ‚áëcoroot) (range ‚áëcoroot)) (‚ä¢ ({ {: = toPerfectPairing, root := root, coroot := coroot, root_coroot_two := root_coroot_two,) :  :=   ['Module R M', '= ‚ãØ }']', '= ‚ãØ }']']']']']']']']']']']']']']']']']']']']']']']']']']\n",
      "\n",
      "CASE 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: theorem AdjoinRoot.smul_mk (R: Type u) (S: Type v) (K: Type w) (inst‚úù¬≤: CommRing R) (f: R[X]) (inst‚úù¬π: DistribSMul S R) (inst‚úù: IsScalarTower S R R) (a ‚ä¢ Quotient.map' (fun => x) ‚ãØ ((mk f) = (mk (a { toFinsupp: = x.1 })) :  :=\n",
      "labels:  ['= x.1 })', '= x.1 })']\n",
      "Generated: theorem AdjoinRoot.smul_mk (R: Type u) (S: Type v) (K: Type w) (inst‚úù¬≤: CommRing R) (f: R[X]) (inst‚úù¬π: DistribSMul S R) (inst‚úù: IsScalarTower S R R) (a ‚ä¢ Quotient.map' (fun => x) ‚ãØ ((mk f) = (mk (a { toFinsupp: = x.1 })) :  :=   ['= x.1 })', '= x.1 })']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']']\n",
      "\n",
      "CASE 9\n",
      "inputs: theorem LinearEquiv.comp_toLinearMap_symm_eq (R: Type u_1) (R‚ÇÅ: Type u_2) (R‚ÇÇ: Type u_3) (R‚ÇÉ: Type u_4) (k: Type u_5) (K: Type u_6) (S: Type u_7) (M: Type u_8) (M‚ÇÅ: Type u_9) (M‚ÇÇ: Type u_10) (M‚ÇÉ: Type u_11) (N‚ÇÅ: Type u_12) (N‚ÇÇ: Type u_13) (N‚ÇÉ: Type u_14) (N‚ÇÑ: Type u_15) (Œπ: Type u_16) (M‚ÇÑ: Type u_17) (inst‚úù¬π‚Å∑: Semiring R) (inst‚úù¬π‚Å∂: Semiring S) (inst‚úù¬π‚Åµ: Semiring R‚ÇÅ) (inst‚úù¬π‚Å¥: Semiring R‚ÇÇ) (inst‚úù¬π¬≥: Semiring R‚ÇÉ) (inst‚úù¬π¬≤: AddCommMonoid M) (inst‚úù¬π¬π: AddCommMonoid M‚ÇÅ) (inst‚úù¬π‚Å∞: AddCommMonoid M‚ÇÇ) (inst‚úù‚Åπ: AddCommMonoid M‚ÇÉ) (inst‚úù‚Å∏: AddCommMonoid M‚ÇÑ) (inst‚úù‚Å∑: AddCommMonoid N‚ÇÅ) (inst‚úù‚Å∂: AddCommMonoid N‚ÇÇ) (module_M: Module R M) (module_S_M‚ÇÇ: Module S M‚ÇÇ) (œÉ: R ‚Üí+* S) (œÉ': S ‚Üí+* R) (re‚ÇÅ: RingHomInvPair œÉ œÉ') (re‚ÇÇ: RingHomInvPair œÉ' œÉ) (e e': M ‚âÉ‚Çõ‚Çó[œÉ] M‚ÇÇ) (module_M‚ÇÅ: Module R‚ÇÅ M‚ÇÅ) (module_M‚ÇÇ: Module R‚ÇÇ M‚ÇÇ) (module_M‚ÇÉ: Module R‚ÇÉ M‚ÇÉ) (module_N‚ÇÅ: Module R‚ÇÅ N‚ÇÅ) (module_N‚ÇÇ: Module R‚ÇÅ N‚ÇÇ) (œÉ‚ÇÅ‚ÇÇ: R‚ÇÅ ‚Üí+* R‚ÇÇ) (œÉ‚ÇÇ‚ÇÉ: R‚ÇÇ ‚Üí+* R‚ÇÉ) (œÉ‚ÇÅ‚ÇÉ: R‚ÇÅ ‚Üí+* R‚ÇÉ) (œÉ‚ÇÇ‚ÇÅ: R‚ÇÇ ‚Üí+* R‚ÇÅ) (œÉ‚ÇÉ‚ÇÇ: R‚ÇÉ ‚Üí+* R‚ÇÇ) (œÉ‚ÇÉ‚ÇÅ: R‚ÇÉ ‚Üí+* R‚ÇÅ) (inst‚úù‚Åµ: RingHomCompTriple œÉ‚ÇÅ‚ÇÇ œÉ‚ÇÇ‚ÇÉ œÉ‚ÇÅ‚ÇÉ) (inst‚úù‚Å¥: RingHomCompTriple œÉ‚ÇÉ‚ÇÇ œÉ‚ÇÇ‚ÇÅ œÉ‚ÇÉ‚ÇÅ) (re‚ÇÅ‚ÇÇ: RingHomInvPair œÉ‚ÇÅ‚ÇÇ œÉ‚ÇÇ‚ÇÅ) (re‚ÇÇ‚ÇÉ: RingHomInvPair œÉ‚ÇÇ‚ÇÉ œÉ‚ÇÉ‚ÇÇ) (inst‚úù¬≥: RingHomInvPair œÉ‚ÇÅ‚ÇÉ œÉ‚ÇÉ‚ÇÅ) (re‚ÇÇ‚ÇÅ: RingHomInvPair œÉ‚ÇÇ‚ÇÅ œÉ‚ÇÅ‚ÇÇ) (re‚ÇÉ‚ÇÇ: RingHomInvPair œÉ‚ÇÉ‚ÇÇ œÉ‚ÇÇ‚ÇÉ) (inst‚úù¬≤: RingHomInvPair œÉ‚ÇÉ‚ÇÅ œÉ‚ÇÅ‚ÇÉ) (e‚ÇÇ‚ÇÉ: M‚ÇÇ ‚âÉ‚Çõ‚Çó[œÉ‚ÇÇ‚ÇÉ] M‚ÇÉ) (inst‚úù¬π: RingHomCompTriple œÉ‚ÇÇ‚ÇÅ œÉ‚ÇÅ‚ÇÉ œÉ‚ÇÇ‚ÇÉ) (inst‚úù: RingHomCompTriple œÉ‚ÇÉ‚ÇÅ œÉ‚ÇÅ‚ÇÇ œÉ‚ÇÉ‚ÇÇ) (f: M‚ÇÇ ‚Üí‚Çõ‚Çó[œÉ‚ÇÇ‚ÇÉ] M‚ÇÉ) : f.comp ‚Üëe‚ÇÅ‚ÇÇ.symm.symm = g ‚Üî g = f.comp ‚Üëe‚ÇÅ‚ÇÇ :=\n",
      "labels: theorem LinearEquiv.comp_toLinearMap_symm_eq (R: Type u_1) (R‚ÇÅ: Type u_2) (R‚ÇÇ: Type u_3) (R‚ÇÉ: Type u_4) (k: Type u_5) (K: Type u_6) (S: Type u_7) (M: Type u_8) (M‚ÇÅ: Type u_9) (M‚ÇÇ: Type u_10) (M‚ÇÉ: Type u_11) (N‚ÇÅ: Type u_12) (N‚ÇÇ: Type u_13) (N‚ÇÉ: Type u_14) (N‚ÇÑ: Type u_15) (Œπ: Type u_16) (M‚ÇÑ: Type u_17) (inst‚úù¬π‚Å∑: Semiring R) (inst‚úù¬π‚Å∂: Semiring S) (inst‚úù¬π‚Åµ: Semiring R‚ÇÅ) (inst‚úù¬π‚Å¥: Semiring R‚ÇÇ) (inst‚úù¬π¬≥: Semiring R‚ÇÉ) (inst‚úù¬π¬≤: AddCommMonoid M) (inst‚úù¬π¬π: AddCommMonoid M‚ÇÅ) (inst‚úù¬π‚Å∞: AddCommMonoid M‚ÇÇ) (inst‚úù‚Åπ: AddComm\n",
      "Generated: theorem LinearEquiv.comp_toLinearMap_symm_eq (R: Type u_1) (R‚ÇÅ: Type u_2) (R‚ÇÇ: Type u_3) (R‚ÇÉ: Type u_4) (k: Type u_5) (K: Type u_6) (S: Type u_7) (M: Type u_8) (M‚ÇÅ: Type u_9) (M‚ÇÇ: Type u_10) (M‚ÇÉ: Type u_11) (N‚ÇÅ: Type u_12) (N‚ÇÇ: Type u_13) (N‚ÇÉ: Type u_14) (N‚ÇÑ: Type u_15) (Œπ: Type u_16) (M‚ÇÑ: Type u_17) (inst‚úù¬π‚Å∑: Semiring R) (inst‚úù¬π‚Å∂: Semiring S) (inst‚úù¬π‚Åµ: Semiring R‚ÇÅ) (inst‚úù¬π‚Å¥: Semiring R‚ÇÇ) (inst‚úù¬π¬≥: Semiring R‚ÇÉ) (inst‚úù¬π¬≤: AddCommMonoid M) (inst‚úù¬π¬π: AddCommMonoid M‚ÇÅ) (inst‚úù¬π‚Å∞: AddCommMonoid M‚ÇÇ) (inst‚úù‚Åπ: AddCommMonoid M‚ÇÉ) (inst‚úù‚Å∏: AddCommMonoid M‚ÇÑ) (inst‚úù‚Å∑: AddCommMonoid N‚ÇÅ) (inst‚úù‚Å∂: AddCommMonoid N‚ÇÇ) (module_M: Module R M) (module_S_M‚ÇÇ: Module S M‚ÇÇ) (œÉ: R ‚Üí+* S) (œÉ': S ‚Üí+* R) (re‚ÇÅ: RingHomInvPair œÉ œÉ') (re‚ÇÇ: RingHomInvPair œÉ' œÉ) (e e': M ‚âÉ‚Çõ‚Çó[œÉ] M‚ÇÇ) (module_M‚ÇÅ: Module R‚ÇÅ M‚ÇÅ) (module_M‚ÇÇ: Module R‚ÇÇ M‚ÇÇ) (module_M‚ÇÉ: Module R‚ÇÉ M‚ÇÉ) (module_N‚ÇÅ: Module R‚ÇÅ N‚ÇÅ) (module_N‚ÇÇ: Module R‚ÇÅ N‚ÇÇ) (œÉ‚ÇÅ‚ÇÇ: R‚ÇÅ ‚Üí+* R‚ÇÇ) (œÉ‚ÇÇ‚ÇÉ: R‚ÇÇ ‚Üí+* R‚ÇÉ) (œÉ‚ÇÅ‚ÇÉ: R‚ÇÅ ‚Üí+* R‚ÇÉ) (œÉ‚ÇÇ‚ÇÅ: R‚ÇÇ ‚Üí+* R‚ÇÅ) (œÉ‚ÇÉ‚ÇÇ: R‚ÇÉ ‚Üí+* R‚ÇÇ) (œÉ‚ÇÉ‚ÇÅ: R‚ÇÉ ‚Üí+* R‚ÇÅ) (inst‚úù‚Åµ: RingHomCompTriple œÉ‚ÇÅ‚ÇÇ œÉ‚ÇÇ‚ÇÉ œÉ‚ÇÅ‚ÇÉ) (inst‚úù‚Å¥: RingHomCompTriple œÉ‚ÇÉ‚ÇÇ œÉ‚ÇÇ‚ÇÅ œÉ‚ÇÉ‚ÇÅ) (re‚ÇÅ‚ÇÇ: RingHomInvPair œÉ‚ÇÅ‚ÇÇ œÉ‚ÇÇ‚ÇÅ) (re‚ÇÇ‚ÇÉ: RingHomInvPair œÉ‚ÇÇ‚ÇÉ œÉ‚ÇÉ‚ÇÇ) (inst‚úù¬≥: RingHomInvPair œÉ‚ÇÅ‚ÇÉ œÉ‚ÇÉ‚ÇÅ) (re‚ÇÇ‚ÇÅ: RingHomInvPair œÉ‚ÇÇ‚ÇÅ œÉ‚ÇÅ‚ÇÇ) (re‚ÇÉ‚ÇÇ: RingHomInvPair œÉ‚ÇÉ‚ÇÇ œÉ‚ÇÇ‚ÇÉ) (inst‚úù¬≤: RingHomInvPair œÉ‚ÇÉ‚ÇÅ œÉ‚ÇÅ‚ÇÉ) (e‚ÇÇ‚ÇÉ: M‚ÇÇ ‚âÉ‚Çõ‚Çó[œÉ‚ÇÇ‚ÇÉ] M‚ÇÉ) (inst‚úù¬π: RingHomCompTriple œÉ‚ÇÇ‚ÇÅ œÉ‚ÇÅ‚ÇÉ œÉ‚ÇÇ‚ÇÉ) (inst‚úù: RingHomCompTriple œÉ‚ÇÉ‚ÇÅ œÉ‚ÇÅ‚ÇÇ œÉ‚ÇÉ‚ÇÇ) (f: M‚ÇÇ ‚Üí‚Çõ‚Çó[œÉ‚ÇÇ‚ÇÉ] M‚ÇÉ) : f.comp ‚Üëe‚ÇÅ‚ÇÇ.symm.symm = g ‚Üî g = f.comp ‚Üëe‚ÇÅ‚ÇÇ :=   ['M ‚âÉ‚Çõ‚Çó[œÉ‚ÇÅ‚ÇÇ] M‚ÇÇ'] (œÉ‚ÇÅ‚ÇÇ.comp ‚Üëe‚ÇÇ‚ÇÉ.symm) f'] (œÉ‚ÇÇ‚ÇÉ.comp ‚Üëe‚ÇÇ\n"
     ]
    }
   ],
   "source": [
    "def predict_hyp(instruction):\n",
    "    input_ids = tokenizer.encode(instruction, return_tensors='pt').to('cuda')\n",
    "\n",
    "    # Generate output\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(input_ids, max_new_tokens=50) #max_length=MAX_LENGTH)\n",
    "\n",
    "    # Decode the generated output and the true labels\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"\\nCASE\", i)\n",
    "    test_case = tokenized_test[i]\n",
    "    generated_text = predict_hyp(test_case['instruction'])\n",
    "    #input_ids = tokenizer.encode(test_case['instruction'], return_tensors='pt').to('cuda')\n",
    "    #print(input_ids)\n",
    "    print(\"inputs:\", test_case['instruction'])\n",
    "    labels = [x for x in test_case['labels'] if x >= 0]\n",
    "    labels = torch.tensor(labels).to('cuda')\n",
    "    print(\"labels:\", tokenizer.decode(labels, skip_special_tokens=True))\n",
    "    #true_text = tokenizer.decode(labels, skip_special_tokens=True)\n",
    "    # Compare the results\n",
    "    print(\"Generated:\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f463488d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"theorem Equiv.embeddingFinSucc_fst (m n‚úù n: ‚Ñï) (Œπ: Type u_1) : ‚áë((embeddingFinSucc n Œπ) e).fst = ‚áëe ‚àò Fin.succ :=   ['Fin (n + 1) ‚Ü™ Œπ'] 'n = 0'] (n + 1)'] (n + 1) = (n + 1)']']'] (n +\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructions = [\n",
    "    \"theorem mul_right_inv (G: Type u_1) (inst‚úù : Group G) (a : G) : a * a‚Åª¬π = 1 :=\",\n",
    "    \"theorem fact1 (a: ‚Ñù) (b: ‚Ñù) : a * b * 2 ‚â§ a ^ 2 + b ^ 2 :=\",\n",
    "    \"theorem x_pos_neg_1 (x: ‚Ñù) : x = 1 ‚à® x = -1 :=\",\n",
    "    \"theorem Equiv.embeddingFinSucc_fst (m n‚úù n: ‚Ñï) (Œπ: Type u_1) : ‚áë((embeddingFinSucc n Œπ) e).fst = ‚áëe ‚àò Fin.succ :=\"\n",
    "    #\"theorem monotone_f (a: ‚Ñù) (b: ‚Ñù) (f‚úù: ‚Ñù ‚Üí ‚Ñù) (h: ‚àÄ {f : ‚Ñù ‚Üí ‚Ñù}, Monotone f ‚Üí ‚àÄ {a b : ‚Ñù}, f a ‚â§ f b ‚Üí a ‚â§ b) (f: ‚Ñù ‚Üí ‚Ñù := fun x ‚Ü¶ 0) : Monotone f :=\"\n",
    "]\n",
    "\n",
    "predict_hyp(instructions[3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "axiom",
   "language": "python",
   "name": "axiom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
